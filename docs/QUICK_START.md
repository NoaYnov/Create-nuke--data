# ğŸš€ Guide de DÃ©marrage Rapide

## PrÃ©requis

- Docker Desktop installÃ© et en cours d'exÃ©cution
- Git (optionnel)

## Installation et Configuration

### 1ï¸âƒ£ Configuration Initiale

```bash
# Copier le fichier de configuration
cp .env.example .env
```

Ã‰ditez `.env` et ajoutez :
- Un **mot de passe sÃ©curisÃ©** pour `POSTGRES_PASSWORD`
- Votre **clÃ© API CurseForge** dans `CURSEFORGE_API_KEY` (optionnel)

### 2ï¸âƒ£ DÃ©marrage des Services

```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tout fonctionne
docker-compose ps
```

Vous devriez voir 4 conteneurs **"Up"** :
- âœ… `createnuclear-postgres`
- âœ… `createnuclear-app`
- âœ… `createnuclear-onepage`
- âœ… `createnuclear-collector`

### 3ï¸âƒ£ AccÃ©der au Dashboard

Ouvrez votre navigateur :
- **Dashboard Principal** : http://localhost:8501
- **Vue SimplifiÃ©e** : http://localhost:8502

## ğŸ“Š PremiÃ¨re Collecte de DonnÃ©es

### Option A : Via le Dashboard (RecommandÃ©)

1. Ouvrez http://localhost:8501
2. Dans la sidebar, cliquez sur **"ğŸ”„ Run Data Collection"**
3. Attendez la fin de la collecte (quelques minutes)

### Option B : Via la Ligne de Commande

```bash
docker-compose exec streamlit-app python src/collectors/collect_stats.py
```

## â° Collecte Automatique

**C'est dÃ©jÃ  configurÃ© !** Le service `stats-collector` collecte automatiquement les donnÃ©es **toutes les 24 heures**.

Pour vÃ©rifier :
```bash
# Voir les logs du collecteur
docker-compose logs -f stats-collector
```

## ğŸ“ˆ Importer des DonnÃ©es Existantes (Optionnel)

Si vous avez des donnÃ©es CSV/JSON Ã  importer :

```powershell
# Windows PowerShell
.\scripts\import_data.ps1
```

```bash
# Linux/Mac
./scripts/import_data.sh
```

## ğŸ” VÃ©rification

### VÃ©rifier la Base de DonnÃ©es

```bash
docker-compose exec streamlit-app python scripts/init_db.py
```

### Voir les Logs

```bash
# Tous les services
docker-compose logs

# Service spÃ©cifique
docker-compose logs streamlit-app
docker-compose logs stats-collector
```

## ğŸ›‘ ArrÃªt des Services

```bash
# ArrÃªter sans supprimer les donnÃ©es
docker-compose stop

# ArrÃªter et supprimer les conteneurs (garde les donnÃ©es)
docker-compose down

# Supprimer TOUT (conteneurs + donnÃ©es)
docker-compose down -v
```

## ğŸ“š Documentation ComplÃ¨te

- **[AUTO_COLLECTION.md](AUTO_COLLECTION.md)** - Configuration de la collecte automatique
- **[POSTGRES_DATA.md](POSTGRES_DATA.md)** - Gestion des donnÃ©es PostgreSQL
- **[README.md](../README.md)** - Documentation gÃ©nÃ©rale du projet

## âš™ï¸ Configuration AvancÃ©e

### Modifier l'Intervalle de Collecte

Ã‰ditez `.env` :
```bash
# 86400 = 24 heures (dÃ©faut)
# 43200 = 12 heures
# 3600 = 1 heure (test)
COLLECTION_INTERVAL=86400
```

Puis redÃ©marrer :
```bash
docker-compose restart stats-collector
```

### Changer les Ports

Ã‰ditez `.env` :
```bash
STREAMLIT_PORT=8501
STREAMLIT_ONEPAGE_PORT=8502
POSTGRES_PORT=5433
```

## ğŸ› ProblÃ¨mes Courants

### "Module not found"
```bash
# Reconstruire les conteneurs
docker-compose up -d --build
```

### "Connection refused" (PostgreSQL)
```bash
# Attendre que PostgreSQL soit prÃªt
docker-compose logs postgres

# VÃ©rifier la santÃ©
docker-compose ps postgres
```

### Les donnÃ©es n'apparaissent pas
```bash
# Forcer une collecte
docker-compose exec streamlit-app python src/collectors/collect_stats.py

# VÃ©rifier la base de donnÃ©es
docker-compose exec streamlit-app python scripts/init_db.py
```

## ğŸ¯ Commandes Utiles

```bash
# RedÃ©marrer tout
docker-compose restart

# Reconstruire et redÃ©marrer
docker-compose up -d --build

# Voir les ressources utilisÃ©es
docker stats

# Nettoyer les logs
docker-compose logs --tail=0 > /dev/null

# Backup de la base de donnÃ©es
docker-compose exec postgres pg_dump -U createnuclear createnuclear_stats > backup.sql
```

## âœ… Checklist de DÃ©marrage

- [ ] Docker Desktop installÃ© et dÃ©marrÃ©
- [ ] Fichier `.env` crÃ©Ã© et configurÃ©
- [ ] Services dÃ©marrÃ©s avec `docker-compose up -d`
- [ ] Tous les conteneurs affichent "Up"
- [ ] Dashboard accessible sur http://localhost:8501
- [ ] PremiÃ¨re collecte lancÃ©e (via bouton ou script)
- [ ] DonnÃ©es visibles dans le dashboard

## ğŸ‰ Vous Ãªtes PrÃªt !

Le systÃ¨me collecte maintenant automatiquement les donnÃ©es toutes les 24 heures et les stocke dans PostgreSQL !

Pour toute question, consultez la documentation ou vÃ©rifiez les logs.
